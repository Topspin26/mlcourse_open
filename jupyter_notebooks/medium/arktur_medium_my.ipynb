{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Соревнование по прогнозированию популярности статьи на портале Medium\n",
    "## <center> Ridge baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ссылка](https://mlcourse.arktur.io/) на соревнование.\n",
    "\n",
    "**Задача** \n",
    "\n",
    "Есть выборка статей с популярного англоязычного портала Medium. Задача – спрогнозировать число рекомендаций (\"лайков\") статьи.\n",
    "Предлагается Вам самим составить обучающую и тестовую выборки на основе имеющихся данных, обучить модель-регрессор и сформировать файл посылки с прогнозами – числом рекомендаций статей (с `log1p`-преобразованием) из тестовой выборки.\n",
    "\n",
    "**Данные**\n",
    "\n",
    "Обучающая выборка – 52699 статей, опубликованных до 2016 года включительно (**train.zip** ~ 480 Mb, unzip ~1.6 Gb). Тестовая выборка – 39492 статьи, опубликованные с 1 января по 27 июня 2017 года (**test.zip** ~425 Mb, unzip ~1.4 Gb).\n",
    "\n",
    "Данные о статьях представлены в JSON формате с полями:\n",
    "- _id и url – URL статьи\n",
    "- published – время публикации\n",
    "- title – название статьи\n",
    "- author – имя автора, его акканут на Твиттере и Medium\n",
    "- content – HTML-контент статьи\n",
    "meta_tags – остальная информация о статье\n",
    "\n",
    "В файле **train_log1p_recommends.csv** представлены номера (id) статей из обучающей выборки вместе с целевым показателем: числом рекомендаций статей, к которому применено преобразование `log1p(x) = log(1 + x)` В файле **sample_submission.csv** представлен пример файла посылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import zlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../data/medium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий код я стащил откуда-то со StackOverflow – он выкидывает из текста HTML-теги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ' '.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим обучающую и тестовую выборки. Забираем из JSON-представления статьи только content (собственно текст статьи), очищаем его от HTML-тегов и записываем в файл. Такой формат подойдет для извлечения признаков (Bag of Words) с помощью `CountVectorizer`. На Mac с SSD это все работает относительно быстро, на Windows без SSD будет скучновато."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_log1p_recommends.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addKV(k, v, meta, t_count):\n",
    "    if k not in meta:\n",
    "        meta[k] = k + '_'#str(len(meta)) + '_'\n",
    "    s = strip_tags(str(v).replace('\\n', ' '))\n",
    "    for i in range(len(s)):\n",
    "        t_count.update([meta[k] + s[i]])\n",
    "        if i < len(s) - 1:\n",
    "            t_count.update([meta[k] + s[i:i+2]])\n",
    "        if i < len(s) - 2:\n",
    "            t_count.update([meta[k] + s[i:i+3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonuniq_words(text):\n",
    "    return [e.lower() for e in re.findall(\"\\w+\", text, re.UNICODE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_json(json_data, meta):\n",
    "    t_counter = Counter()\n",
    "    for k, v in json_data.items():\n",
    "        if k == 'quality':\n",
    "            continue\n",
    "        if isinstance(v, dict):\n",
    "            for k1, v1 in v.items():\n",
    "                #print(k, k1, v1)\n",
    "                addKV(k + '\\t' + k1, v1, meta, t_counter)\n",
    "        else:\n",
    "            #print(k, v)\n",
    "            addKV(k, v, meta, t_counter)\n",
    "    return t_counter\n",
    "\n",
    "def getFeatures(json_data):\n",
    "    sc = json_data['content']\n",
    "    tc = nonuniq_words(sc)\n",
    "\n",
    "    st = json_data['title']\n",
    "    tt = nonuniq_words(st)\n",
    "\n",
    "    return [np.log(1 + len(sc)),\n",
    "                 np.log(1 + len(tc)),\n",
    "                 len(set(tc)) / len(tc),\n",
    "                 len(zlib.compress(sc.encode('utf-8'))) / len(sc.encode('utf-8')),\n",
    "                 np.log(1 + len(st)),\n",
    "                 np.log(1 + len(tt)),\n",
    "                 len(set(tt)) / len(tt),\n",
    "                 len(zlib.compress(st.encode('utf-8'))) / len(st.encode('utf-8')),\n",
    "                 int(sc.find('<img') != -1),\n",
    "                 int(sc.find('.gif') != -1)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium Blocked Unblock Follow Following Everyone’s stories and ideas Aug 13, 2012 Medium Terms of Service Effective: March 7, 2016 These Terms of Service (“Terms”) are a contract between you and A Medium Corporation. They govern your use of Medium’s sites, services, mobile apps, products, and content (“Services”). By using Medium, you agree to these Terms. If you don’t agree to any of the Terms, you can’t use Medium. We can change these Terms at any time. We keep a  historical  record of all changes to our Terms on GitHub. If a change is material, we’ll let you know before they take effect. By using Medium on or after that effective date, you agree to the new Terms. If you don’t agree to them, you should delete your account before they take effect, otherwise your use of the site and content will be subject to the new Terms. Content rights & responsibilities You own the rights to the content you create and post on Medium. By posting content to Medium, you give us a nonexclusive license to publish it on Medium Services, including anything reasonably related to publishing it (like storing, displaying, reformatting, and distributing it). In consideration for Medium granting you access to and use of the Services, you agree that Medium may enable advertising on the Services, including in connection with the display of your content or other information. We may also use your content to promote Medium, including its products and content. We will never sell your content to third parties without your explicit permission. You’re responsible for the content you post. This means you assume all risks related to it, including someone else’s reliance on its accuracy, or claims relating to intellectual property or other legal rights. You’re welcome to post content on Medium that you’ve published elsewhere, as long as you have the rights you need to do so. By posting content to Medium, you represent that doing so doesn’t conflict with any other agreement you’ve made. By posting content you didn’t create to Medium, you are representing that you have the right to do so. For example, you are posting a work that’s in the public domain, used under license (including a free license, such as  Creative Commons ), or a fair use. We can remove any content you post for any reason. You can delete any of your posts, or your account, anytime. Processing the deletion may take a little time, but we’ll do it as quickly as possible. We may keep backup copies of your deleted post or account on our servers for up to 14 days after you delete it. Our content and services We reserve all rights in Medium’s look and feel. Some parts of Medium are licensed under third-party open source licenses. We also make some of our own code available under open source licenses. As for other parts of Medium, you may not copy or adapt any portion of our code or visual design elements (including logos) without express written permission from Medium unless otherwise permitted by law. You may not do, or try to do, the following: (1) access or tamper with non-public areas of the Services, our computer systems, or the systems of our technical providers; (2) access or search the Services by any means other than the currently available, published interfaces (e.g., APIs) that we provide; (3) forge any TCP/IP packet header or any part of the header information in any email or posting, or in any way use the Services to send altered, deceptive, or false source-identifying information; or (4) interfere with, or disrupt, the access of any user, host, or network, including sending a virus, overloading, flooding, spamming, mail-bombing the Services, or by scripting the creation of content or accounts in such a manner as to interfere with or create an undue burden on the Services. Crawling the Services is allowed if done in accordance with the provisions of our robots.txt file, but scraping the Services is prohibited. We may change, terminate, or restrict access to any aspect of the service, at any time, without notice. No children Medium is only for people 13 years old and over. By using Medium, you affirm that you are over 13. If we learn someone under 13 is using Medium, we’ll terminate their account. Security If you find a security vulnerability on Medium, tell us. We have a  bug bounty disclosure program . Incorporated rules and policies By using the Services, you agree to let Medium collect and use information as detailed in our  Privacy Policy . If you’re outside the United States, you consent to letting Medium transfer, store, and process your information (including your personal information and content) in and out of the United States. To enable a functioning community, we have  Rules . To ensure usernames are distributed and used fairly, we have a  Username Policy . Under our  DMCA Policy , we’ll remove material after receiving a valid takedown notice. Under our  Trademark Policy , we’ll investigate any use of another’s trademark and respond appropriately. By using Medium, you agree to follow these Rules and Policies. If you don’t, we may remove content, or suspend or delete your account. Miscellaneous Disclaimer of warranty.  Medium provides the Services to you as is. You use them at your own risk and discretion. That means they don’t come with any warranty. None express, none implied. No implied warranty of merchantability, fitness for a particular purpose, availability, security, title or non-infringement. Limitation of Liability . Medium won’t be liable to you for any damages that arise from your using the Services. This includes if the Services are hacked or unavailable. This includes all types of damages (indirect, incidental, consequential, special or exemplary). And it includes all kinds of legal claims, such as breach of contract, breach of warranty, tort, or any other loss. No waiver.  If Medium doesn’t exercise a particular right under these Terms, that doesn’t waive it. Severability . If any provision of these terms is found invalid by a court of competent jurisdiction, you agree that the court should try to give effect to the parties’ intentions as reflected in the provision and that other provisions of the Terms will remain in full effect. Choice of law and jurisdiction.  These Terms are governed by California law, without reference to its conflict of laws provisions. You agree that any suit arising from the Services must take place in a court located in San Francisco, California. Entire agreement.  These Terms (including any document incorporated by reference into them) are the whole agreement between Medium and you concerning the Services. Government use.  If you’re ​using ​Medium for the U.S. Government,  this Amendment  to ​Medium’s Terms of Service ​applies to you​. Questions? Let us know at  legal@medium.com . Terms And Conditions Terms Medium 1K 47 Blocked Unblock Follow Following Medium Everyone’s stories and ideas Follow Medium Policy The Fine Print\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium Blocked Unblock Follow Following Everyone’s stories and ideas Aug 13, 2012 Medium Privacy Policy Effective Date: March 7, 2016 Privacy is important. We respect yours. Our goal is to do more than we have to by law — we want to earn your trust that we are careful with your data. General information This policy sets out our privacy practices and explains how we handle the information we collect when you visit and use our sites, services, mobile applications, products, and content (“Services”). What we may collect We collect information about what Medium pages you access, information about your mobile device (such as device or browser type), information you send us (such as an email address used to register or communicate with us), and referral information. When you use Medium Services, we may collect and store your Internet Protocol address. We may use this information to fight spam and other abuse; to personalize Medium Services; or to generate aggregate, non-identifying information about how people use Medium Services. When you create your Medium account, and authenticate via a third-party service like Twitter or Facebook, we may collect, store, and periodically update the contact lists associated with that third-party account, so you can connect with existing contacts from that service who are on Medium. Email from Medium Sometimes we’ll send administrative emails about account or service changes, or new policies. You can’t opt out of them. You can always opt out of non-administrative emails such as daily digests. We won’t email you to ask for your password or other account information. If you receive such an email, send it to us so we can investigate. Disclosure of your information As a rule, we don’t share your personal information outside the company. We won’t sell your personal information. We may share your personal information with third parties in limited circumstances, including: (1) with your consent; (2) to a vendor or partner who meets our data protection standards; or (3) when we have a good faith belief it is required by law, such as pursuant to a subpoena or other legal process. If we’re going to share your information in response to legal process, we’ll give you advance notice so you can challenge it (for example by seeking court intervention), unless we’re prohibited from doing so by law or court order. We will object to requests for information about users of our site that we believe to be improper. If we merge with another company such that your information will become subject to a different privacy policy, we’ll notify you before the transfer. You can opt out of the new policy by deleting your account during the notice period. Cookies We use cookies and similar technologies such as pixels and local storage to recognize you when you return to our Services. We use them in various ways, for example to log you in, remember your preferences (such as default language), evaluate email effectiveness, show relevant ads, and personalize information. We respect  Do Not Track  (“DNT”) settings in browsers. If you’re logged out of our Services and have DNT enabled, we will not set cookies. By logging in you are opting to allow Medium to ignore the DNT setting and to use cookies in order to provide you a personalized experience. Some third-party services that we use, such as  embedly  or  Google Analytics , may place their own cookies in your browser. This Privacy Policy covers use of cookies by Medium only and not the use of cookies by third parties. Data Storage Medium uses third-party vendors and hosting partners, such as Amazon, for hardware, software, networking, storage, and related technology we need to run Medium. We  maintain two types of logs : server logs and event logs. Modifying your personal information or deleting your account If you have a Medium account, you can access and modify your personal information, or delete your account  here . To protect information from accidental or malicious destruction, we may not immediately delete residual copies from our active servers and may not remove information from our backup systems. If you delete your account, your account and content may be unrecoverable. Data security We use encryption (HTTPS/TLS) to protect data transmitted to and from our site. However, no data transmission over the Internet is 100% secure, so we can’t guarantee security. You use the Service at your own risk, and you’re responsible for taking reasonable measures to secure your account (like using a strong password). Changes to this Policy Medium may periodically update this Policy. We’ll notify you about significant changes to it. The most current version of the policy will always be  here  and we will archive former versions of the policy  here . Questions We welcome questions, concerns, and feedback about this policy at  legal@medium.com . Some rights reserved   Privacy Medium 396 34 Blocked Unblock Follow Following Medium Everyone’s stories and ideas Follow Medium Policy The Fine Print\n",
      "Wall time: 9.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ngr_dict = dict()\n",
    "meta = dict()\n",
    "\n",
    "t_counter_list = []\n",
    "dt_list = []\n",
    "X_tr = []\n",
    "with open(os.path.join(PATH_TO_DATA, 'train.json'), encoding='utf-8') as inp_json_file, \\\n",
    "     open(os.path.join(PATH_TO_DATA, 'train_raw_content.txt'), 'w', encoding='utf-8') \\\n",
    "     as out_raw_text_file:\n",
    "     \n",
    "    i = 0\n",
    "    for line in inp_json_file:\n",
    "        json_data = json.loads(line)\n",
    "        print(strip_tags(json_data['content']))\n",
    "        i += 1\n",
    "        if i == 2:\n",
    "            break\n",
    "        continue\n",
    "        target = float(json_data['quality']['recommends'])\n",
    "        dt = json_data['published']['$date'][:7]\n",
    "        if not dt in ngr_dict:\n",
    "            ngr_dict[dt] = dict()\n",
    "\n",
    "        t_counter = process_json(json_data, meta)\n",
    "\n",
    "        t_counter_list.append(t_counter)\n",
    "        dt_list.append(dt)\n",
    "        for ek, ev in t_counter.items():\n",
    "            if ek not in ngr_dict[dt]:\n",
    "                ngr_dict[dt][ek] = [0, 0]\n",
    "            ngr_dict[dt][ek][0] += np.log(1 + ev)\n",
    "            ngr_dict[dt][ek][1] += y_train[i]            \n",
    "        i += 1\n",
    "\n",
    "        features = getFeatures(json_data)\n",
    "        X_tr.append(features)\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        if i == 10000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngr_dict_cum = dict()\n",
    "next_dict = dict()\n",
    "for e in sorted(ngr_dict.keys()):\n",
    "    ngr_dict_cum[e] = next_dict.copy()\n",
    "    \n",
    "    for k, v in ngr_dict[e].items():\n",
    "        if k not in next_dict:\n",
    "            next_dict[k] = [0, 0]\n",
    "        next_dict[k][0] += v[0]\n",
    "        next_dict[k][1] += v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2007-02', '2008-06', '2008-09', '2010-08', '2011-03', '2011-07', '2011-08', '2011-09', '2011-10', '2011-11', '2012-01', '2012-07', '2012-08', '2012-09', '2012-10', '2012-11', '2012-12', '2013-01', '2013-02', '2013-03', '2013-04', '2013-05', '2013-06', '2013-07', '2013-08', '2013-09', '2013-10', '2013-11', '2013-12', '2014-01', '2014-02', '2014-03', '2014-04', '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11', '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(ngr_dict_cum.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251261"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngr_dict_cum['2016-12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('content_K 1', [86.50986617736865, 749.11580000000004]),\n",
       " ('content_1K ', [72.492771886342481, 620.34753999999987]),\n",
       " ('content_.1K', [42.975125194716604, 394.33731000000012]),\n",
       " ('content_3K ', [41.588830833596703, 379.04313999999999]),\n",
       " ('content_3K', [46.153179025064546, 406.57934]),\n",
       " ('content_K 3', [40.60800158058499, 365.47115000000002]),\n",
       " ('link_tags\\tamphtml_am', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_/am', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_/p/', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_mp', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_mp/', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_m', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_/p', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_amp', [50.599744180876009, 435.07601999999997]),\n",
       " ('link_tags\\tamphtml_p/p', [50.599744180876009, 435.07601999999997]),\n",
       " ('content_K 2', [45.460031844504606, 396.15069999999997]),\n",
       " ('content_K 4', [35.350506208557199, 323.42873999999995]),\n",
       " ('content_.2K', [37.142265677785268, 334.27312000000001]),\n",
       " ('content_2K ', [57.40213894420031, 474.81768]),\n",
       " ('link_tags\\tamphtml_/a', [51.816139505200496, 435.07601999999997])]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ngr_dict_cum['2016-12'].items(), key=lambda x: -(x[1][1] / (x[1][0] + 10)))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngr2num = dict(zip(sorted(ngr_dict_cum['2016-12'].keys()), range(len(ngr_dict_cum['2016-12']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "i = 0\n",
    "for t_counter, dt in zip(t_counter_list, dt_list):\n",
    "    for ek, ev in t_counter.items():\n",
    "        if ek in ngr_dict_cum[dt]:\n",
    "            row.append(i)\n",
    "            col.append(ngr2num[ek])\n",
    "            w1, w2 = ngr_dict_cum[dt][ek]\n",
    "            w = w2 / (w1 + 10)\n",
    "            data.append(w * np.log(1 + ev))\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_sparse = csr_matrix((data, (row, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x1251255 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 65678692 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_tr)\n",
    "df['year'] = [int(e[:4]) - 2012 for e in dt_list]\n",
    "df['month'] = [int(e[5:]) / 12 for e in dt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sparse = hstack([X_sparse, df.values]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_reg = Ridge(random_state=17, alpha=2e4)\n",
    "ridge_reg.fit(X_sparse[:8000, :], y_train[:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_valid_pred = ridge_reg.predict(X_sparse[8000:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90604035472652977"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train[8000:10000], ridge_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_valid_pred = ridge_reg.predict(X_sparse[:8000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5907906646669725"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train[:8000], ridge_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_reg = Ridge(random_state=17, alpha=2e4)\n",
    "ridge_reg.fit(X_sparse[:10000, :], y_train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n",
      "25000\n",
      "25500\n",
      "26000\n",
      "26500\n",
      "27000\n",
      "27500\n",
      "28000\n",
      "28500\n",
      "29000\n",
      "29500\n",
      "30000\n",
      "30500\n",
      "31000\n",
      "31500\n",
      "32000\n",
      "32500\n",
      "33000\n",
      "33500\n",
      "34000\n",
      "34500\n",
      "35000\n",
      "35500\n",
      "36000\n",
      "36500\n",
      "37000\n",
      "37500\n",
      "38000\n",
      "38500\n",
      "39000\n",
      "Wall time: 53min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = []\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA, 'test.json')) as inp_json_file, \\\n",
    "     open(os.path.join(PATH_TO_DATA, 'test_raw_content.txt'), 'w') \\\n",
    "     as out_raw_text_file:\n",
    "            \n",
    "    i = 0\n",
    "    for line in inp_json_file:\n",
    "        json_data = json.loads(line)\n",
    "\n",
    "        dt = json_data['published']['$date'][:7]\n",
    "        if not dt in ngr_dict:\n",
    "            ngr_dict[dt] = dict()\n",
    "\n",
    "        t_counter = process_json(json_data, meta)\n",
    "        features = getFeatures(json_data)\n",
    "        df = pd.DataFrame([features])\n",
    "        df['year'] = [int(e[:4]) - 2012 for e in [dt]]\n",
    "        df['month'] = [int(e[5:]) / 12 for e in [dt]]\n",
    "        \n",
    "        row = [0]\n",
    "        col = [X_sparse.shape[1] - df.shape[1] - 1]\n",
    "        data = [0]\n",
    "        for ek, ev in t_counter.items():\n",
    "            if ek in ngr_dict_cum['2016-12']:\n",
    "                row.append(0)\n",
    "                col.append(ngr2num[ek])\n",
    "                w1, w2 = ngr_dict_cum['2016-12'][ek]\n",
    "                w = w2 / (w1 + 10)\n",
    "                data.append(w * np.log(1 + ev))\n",
    "        \n",
    "        X = hstack([csr_matrix((data, (row, col))), df.values]).tocsr()\n",
    "        preds += list(ridge_reg.predict(X))\n",
    "        i += 1\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "        #if i == 500:\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39492"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   223.,   4793.,  12948.,  11907.,   6067.,   2296.,    850.,\n",
       "           292.,     93.,     23.]),\n",
       " array([-0.43623658,  0.45462312,  1.34548281,  2.23634251,  3.12720221,\n",
       "         4.0180619 ,  4.9089216 ,  5.79978129,  6.69064099,  7.58150069,\n",
       "         8.47236038]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2947c8438d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь как раз применяем `CountVectorizer`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем смотреть на качество (MAE) на 30% данных, причем не перемешиваем данные, а соблюдаем время – проверочная часть четко по времени после обучающей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем прогнозы в файл. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA,\n",
    "                                        'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission_file(preds, \n",
    "                      os.path.join(PATH_TO_DATA, 'first_my.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сделать посылку на [сайте](https://mlcourse.arktur.io/dashboard?problem=MLCourse) соревнования, то получится воспроизведение бенчмарка \"Content only, Ridge + CountVectorizer\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
